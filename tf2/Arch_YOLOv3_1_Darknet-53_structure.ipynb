{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv2寫一半，有一次在尹相志老師的臉書上的留言提到自己還在寫YOLOv2，他說，從v3開始就好了，所以我就決定就從v3開始寫就好了。我相信即使到現在有v7(2022-08-01)，v3還是非常的實用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面先給出眾多的參考資料，瞭解一個架構不容易，參考的自然也多了，正確的寫出引用、參照是學習過程中的必要："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)\n",
    "* [pjreddie/darknet](https://github.com/pjreddie/darknet)\n",
    "* [YOLOv3_論文翻譯連結](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FryHg904h9)\n",
    "* [YOLOv3深度解析](https://blog.csdn.net/leviopku/article/details/82660381)\n",
    "* [qqwweee/keras-yolo3](https://github.com/qqwweee/keras-yolo3)\n",
    "* [YunYang1994/tensorflow-yolov3](https://github.com/YunYang1994/tensorflow-yolov3)\n",
    "* [joymyhome_Yolov3 config file中pad的理解](https://blog.csdn.net/joymyhome/article/details/106349084)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相關前置資料的處理可以參考另作[Arch_YOLOv2_dataset_preprocess.ipynb](https://github.com/shaoeChen/deeplearning/blob/master/tf2/Arch_YOLOv2_dataset_preprocess.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的docker上執行的版本為tensorflow 2.1，雖然現在流行人生苦短我用PyTorch，不過我還是先繼續tf + keras。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定使用的gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整個模型的話可以從[作者的git](https://github.com/pjreddie/darknet/blob/master/cfg/darknet53.cfg)上查到，因為他在論文中放的資料應該是比較概略，所以如果單純的從論文來看的話應該只能知道架構而不知道細節。最主要在裡面用了大量的residual block，也因此整個網路深到53層，命名為Darnket-53。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "關於Residual的部份，如果有興趣的話也可以參考在下：\n",
    "1. [git_tf2/Arch_ResNet50](https://github.com/shaoeChen/deeplearning/blob/master/tf2/Arch_ResNet50.ipynb)\n",
    "2. [論文翻譯ResNet](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FSy_e1mCEU)\n",
    "\n",
    "當然這裡面還會有network in network的觀念，如果有興趣都可以再延伸閱讀。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我們先來建構模型，同時也給出論文中的模型架構，方便閱讀：  \n",
    "<img src=\"https://hackmd.io/_uploads/SyeUzk_2c.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來就可以開始處理模型的部份了，為了能夠更詳細的說明，我在這邊就分段的說明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先是最一開始進入的conv layer，根據上面的架構圖，這有著32個filter，並且filter size為3x3，如果你有看官方架構文件的話，這邊也有做往外一個pixel的padding，也因此第一個conv layer輸出的大小依然為256x256，並且有32個filters，所以為256x256x32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_53(input_shape: tuple):\n",
    "    \"\"\"模型的概略部份可以參考上圖，詳細部份記得去看作者的git\"\"\"\n",
    "    x_input = tf.keras.layers.Input(input_shape)\n",
    "        \n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same')(x_input)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn1')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=x_input, outputs=x, name='YOLOv3')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "darknet = darknet_53(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLOv3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 32)      0         \n",
      "=================================================================\n",
      "Total params: 1,024\n",
      "Trainable params: 960\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "darknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當然我們知道，第二個conv layer的架構是一樣的，只有filter的數量還有stride之類的些許差異，所以為了模型版面的整潔，我們就設置一個函數來處理標準捲積的動作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有去看官方文件中的darknet53.cfg的話，應該就會發現有一個pad=1的參數，基本上，整個YOLOv3的pad都是1，這個1一直到後來我才知道並非指每個方向都外推1個pixel，而是代表`(kernel size - 1) / 2`，所以filter size=3的情況下，就會是外推2個pixel(直接進位)。\n",
    "\n",
    "相關的計算也可以參考吳恩達老師的[深度學習課程](https://hackmd.io/@shaoeChen/BJDUj508z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 捲積之後的維度為$\\dfrac{n+2p-f}{s} + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以架構圖來看，這會有兩種情況：\n",
    "1. 輸入之後的維度不變，代表它做了same padding，filter size為3x3，帶入公式來看，(256 + 2p - 3) / 1 + 1= 256，2p = 2，因此p = 1，不過這不用我們處理，我們直接把參數的部份設置`padding=same`\n",
    "2. 執行downsampling，(256 + 2p - 3) / 2 + 1 = 128，因此p = 0.5，2p = 1，當p = 1的時候就是四邊都推，p = 0.5的時候就當做是只邊兩邊，我是這樣想的啦，不然課程中是有提到直接採rounddown的方式，但其實設置same padding的話結果是一樣的，也許在論文中有特別指出指定的外推方向是我沒有注意到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_conv(input_x, filters: int, filter_size: tuple, name: str, strides: int = 1):\n",
    "    \"\"\"處理常規的捲積\n",
    "    \n",
    "    input_x: input tensor\n",
    "    filters: filter的數量\n",
    "    filter_size: filter size, ex (3, 3), (1, 1)\n",
    "    strides: 步幅，如果downsampling就會設置為2\n",
    "        _is_downsampling: 是否為下採樣，是的話就外推兩個邊，這部份可以透過strides來做判斷\n",
    "    \n",
    "    \"\"\" \n",
    "    _padding = 'same'\n",
    "    \n",
    "    if strides == 2:\n",
    "        input_x = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)), name=name + '_zero_padding')(input_x)\n",
    "        _padding = 'valid'\n",
    "        \n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=filters, \n",
    "                               kernel_size=filter_size, \n",
    "                               strides=strides,\n",
    "                               name=name + '_conv_1',\n",
    "                               padding=_padding\n",
    "                              )(input_x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=name + '_bn_2')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(name=name + '_leaky_3')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_53(input_shape: tuple):\n",
    "    \"\"\"模型的概略部份可以參考上圖，詳細部份記得去看作者的git\"\"\"\n",
    "    x_input = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = common_conv(x_input, filters=32, filter_size=(3, 3), name='layer_1', strides=1)\n",
    "    x = common_conv(x, filters=32, filter_size=(3, 3), name='layer_2', strides=2)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=x_input, outputs=x, name='YOLOv3')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLOv3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv_1 (Conv2D)      (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "layer_1_bn_2 (BatchNormaliza (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "layer_1_leaky_3 (LeakyReLU)  (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "layer_2_zero_padding (ZeroPa (None, 257, 257, 32)      0         \n",
      "_________________________________________________________________\n",
      "layer_2_conv_1 (Conv2D)      (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "layer_2_bn_2 (BatchNormaliza (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "layer_2_leaky_3 (LeakyReLU)  (None, 128, 128, 32)      0         \n",
      "=================================================================\n",
      "Total params: 10,400\n",
      "Trainable params: 10,272\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "darknet = darknet_53(input_shape)\n",
    "darknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果來看，我們的函數設置應該是正確的才對，接續著就是殘差的處理，前一個layer的output，也就是這個layer的input會跟這個layer的output做相加的動作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這邊我們會先定義一個函數來處理這個殘差塊的部份，很明顯的，每一個架構區塊都是重複的，兩個conv layer，然後做residual處理。而且我們可以再發現一個點，進入residual block之前的output會跟residual block的output的filter數量是一致的，而且input、output維度也是一致的。這意謂著我們可以很輕易的把input與output相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(pre_output, filter_list: tuple, name_list: list):\n",
    "    \"\"\"從論文中的架構圖可以看的出來，residual block是由兩個conv layer建構起來\n",
    "    \n",
    "    pre_output: 前一個layer的output\n",
    "    filter_list:  兩次捲積的filter數量\n",
    "    name_list: 兩次捲積的layer name    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(filter_list) == 2    \n",
    "    filter_nums_1, filter_nums_2 = filter_list\n",
    "    layer_name_1 = 'layer_' + str(name_list[0])\n",
    "    layer_name_2 = 'layer_' + str(name_list[1])\n",
    "    \n",
    "    x = common_conv(pre_output, filters=filter_nums_1, filter_size=(1, 1), name=layer_name_1, strides=1)\n",
    "    x = common_conv(x, filters=filter_nums_2, filter_size=(3, 3), name=layer_name_2, strides=1)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([x, pre_output])\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就可以真正的來設置Darknet-53的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_53(input_shape: tuple):\n",
    "    \"\"\"模型的概略部份可以參考上圖，詳細部份記得去看作者的git\"\"\"\n",
    "    x_input = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = common_conv(x_input, filters=32, filter_size=(3, 3), name='layer_1', strides=1)\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=64, filter_size=(3, 3), name='layer_2', strides=2)    \n",
    "    # 1x\n",
    "    x = residual_block(x, filter_list=(32, 64), name_list=[3, 4])\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=128, filter_size=(3, 3), name='layer_5', strides=2)\n",
    "    # 2x\n",
    "    x = residual_block(x, filter_list=(64, 128), name_list=[6, 7])\n",
    "    x = residual_block(x, filter_list=(64, 128), name_list=[8, 9])\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=256, filter_size=(3, 3), name='layer_10', strides=2)\n",
    "    # 8x\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[11, 12])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[13, 14])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[15, 16])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[17, 18])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[19, 20])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[21, 22])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[23, 24])\n",
    "    x = residual_block(x, filter_list=(128, 256), name_list=[25, 26])\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=512, filter_size=(3, 3), name='layer_27', strides=2)\n",
    "    # 8x\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[28, 29])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[30, 31])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[32, 33])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[34, 35])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[36, 37])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[38, 39])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[40, 41])\n",
    "    x = residual_block(x, filter_list=(256, 512), name_list=[42, 43])\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=1024, filter_size=(3, 3), name='layer_44', strides=2)\n",
    "    # 4x\n",
    "    x = residual_block(x, filter_list=(512, 1024), name_list=[45, 46])\n",
    "    x = residual_block(x, filter_list=(512, 1024), name_list=[47, 48])\n",
    "    x = residual_block(x, filter_list=(512, 1024), name_list=[49, 50])\n",
    "    x = residual_block(x, filter_list=(512, 1024), name_list=[51, 52])\n",
    "    # global average pool\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), name='avg_pooling')(x)\n",
    "    # fully connected and softmax\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=1000, \n",
    "                              activation='softmax', \n",
    "                              name='softmax', \n",
    "                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=10)\n",
    "                             )(x)\n",
    "    model = tf.keras.models.Model(inputs=x_input, outputs=x, name='Darknet-53')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Darknet-53\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_conv_1 (Conv2D)         (None, 256, 256, 32) 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_bn_2 (BatchNormalizatio (None, 256, 256, 32) 128         layer_1_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_leaky_3 (LeakyReLU)     (None, 256, 256, 32) 0           layer_1_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_zero_padding (ZeroPaddi (None, 257, 257, 32) 0           layer_1_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_conv_1 (Conv2D)         (None, 128, 128, 64) 18496       layer_2_zero_padding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_bn_2 (BatchNormalizatio (None, 128, 128, 64) 256         layer_2_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_leaky_3 (LeakyReLU)     (None, 128, 128, 64) 0           layer_2_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_conv_1 (Conv2D)         (None, 128, 128, 32) 2080        layer_2_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_bn_2 (BatchNormalizatio (None, 128, 128, 32) 128         layer_3_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_leaky_3 (LeakyReLU)     (None, 128, 128, 32) 0           layer_3_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_conv_1 (Conv2D)         (None, 128, 128, 64) 18496       layer_3_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_bn_2 (BatchNormalizatio (None, 128, 128, 64) 256         layer_4_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_leaky_3 (LeakyReLU)     (None, 128, 128, 64) 0           layer_4_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 64) 0           layer_4_leaky_3[0][0]            \n",
      "                                                                 layer_2_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_zero_padding (ZeroPaddi (None, 129, 129, 64) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_conv_1 (Conv2D)         (None, 64, 64, 128)  73856       layer_5_zero_padding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_bn_2 (BatchNormalizatio (None, 64, 64, 128)  512         layer_5_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_leaky_3 (LeakyReLU)     (None, 64, 64, 128)  0           layer_5_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_6_conv_1 (Conv2D)         (None, 64, 64, 64)   8256        layer_5_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_6_bn_2 (BatchNormalizatio (None, 64, 64, 64)   256         layer_6_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_6_leaky_3 (LeakyReLU)     (None, 64, 64, 64)   0           layer_6_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_7_conv_1 (Conv2D)         (None, 64, 64, 128)  73856       layer_6_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_7_bn_2 (BatchNormalizatio (None, 64, 64, 128)  512         layer_7_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_7_leaky_3 (LeakyReLU)     (None, 64, 64, 128)  0           layer_7_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 128)  0           layer_7_leaky_3[0][0]            \n",
      "                                                                 layer_5_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_8_conv_1 (Conv2D)         (None, 64, 64, 64)   8256        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_8_bn_2 (BatchNormalizatio (None, 64, 64, 64)   256         layer_8_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_8_leaky_3 (LeakyReLU)     (None, 64, 64, 64)   0           layer_8_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_9_conv_1 (Conv2D)         (None, 64, 64, 128)  73856       layer_8_leaky_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_9_bn_2 (BatchNormalizatio (None, 64, 64, 128)  512         layer_9_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_9_leaky_3 (LeakyReLU)     (None, 64, 64, 128)  0           layer_9_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 128)  0           layer_9_leaky_3[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_10_zero_padding (ZeroPadd (None, 65, 65, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_10_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_10_zero_padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_10_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_10_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_10_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_10_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_11_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       layer_10_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_11_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_11_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_11_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_11_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_12_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_11_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_12_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_12_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_12_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_12_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 256)  0           layer_12_leaky_3[0][0]           \n",
      "                                                                 layer_10_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_13_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_13_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_13_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_13_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_13_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_14_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_13_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_14_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_14_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_14_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_14_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 256)  0           layer_14_leaky_3[0][0]           \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_15_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_15_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_15_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_15_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_15_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_16_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_15_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_16_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_16_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_16_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_16_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 256)  0           layer_16_leaky_3[0][0]           \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_17_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_17_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_17_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_17_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_17_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_18_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_17_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_18_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_18_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_18_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_18_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 256)  0           layer_18_leaky_3[0][0]           \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_19_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_19_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_19_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_19_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_19_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_20_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_19_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_20_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_20_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_20_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_20_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 256)  0           layer_20_leaky_3[0][0]           \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_21_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_21_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_21_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_21_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_21_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_22_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_21_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_22_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_22_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_22_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_22_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 256)  0           layer_22_leaky_3[0][0]           \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_23_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_23_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_23_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_23_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_23_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_24_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_23_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_24_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_24_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_24_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_24_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 256)  0           layer_24_leaky_3[0][0]           \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_25_conv_1 (Conv2D)        (None, 32, 32, 128)  32896       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_25_bn_2 (BatchNormalizati (None, 32, 32, 128)  512         layer_25_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_25_leaky_3 (LeakyReLU)    (None, 32, 32, 128)  0           layer_25_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_26_conv_1 (Conv2D)        (None, 32, 32, 256)  295168      layer_25_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_26_bn_2 (BatchNormalizati (None, 32, 32, 256)  1024        layer_26_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_26_leaky_3 (LeakyReLU)    (None, 32, 32, 256)  0           layer_26_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 256)  0           layer_26_leaky_3[0][0]           \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_27_zero_padding (ZeroPadd (None, 33, 33, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_27_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_27_zero_padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_27_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_27_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_27_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_27_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_28_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      layer_27_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_28_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_28_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_28_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_28_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_29_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_28_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_29_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_29_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_29_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_29_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 512)  0           layer_29_leaky_3[0][0]           \n",
      "                                                                 layer_27_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_30_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_30_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_30_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_30_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_30_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_31_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_30_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_31_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_31_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_31_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_31_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 512)  0           layer_31_leaky_3[0][0]           \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_32_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_32_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_32_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_32_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_32_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_33_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_32_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_33_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_33_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_33_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_33_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 512)  0           layer_33_leaky_3[0][0]           \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_34_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_34_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_34_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_34_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_34_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_35_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_34_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_35_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_35_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_35_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_35_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 512)  0           layer_35_leaky_3[0][0]           \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_36_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_36_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_36_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_36_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_36_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_37_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_36_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_37_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_37_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_37_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_37_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 512)  0           layer_37_leaky_3[0][0]           \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_38_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_38_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_38_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_38_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_38_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_39_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_38_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_39_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_39_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_39_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_39_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 512)  0           layer_39_leaky_3[0][0]           \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_40_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_40_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_40_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_40_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_40_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_41_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_40_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_41_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_41_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_41_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_41_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 512)  0           layer_41_leaky_3[0][0]           \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_42_conv_1 (Conv2D)        (None, 16, 16, 256)  131328      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_42_bn_2 (BatchNormalizati (None, 16, 16, 256)  1024        layer_42_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_42_leaky_3 (LeakyReLU)    (None, 16, 16, 256)  0           layer_42_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_43_conv_1 (Conv2D)        (None, 16, 16, 512)  1180160     layer_42_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_43_bn_2 (BatchNormalizati (None, 16, 16, 512)  2048        layer_43_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_43_leaky_3 (LeakyReLU)    (None, 16, 16, 512)  0           layer_43_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 512)  0           layer_43_leaky_3[0][0]           \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_44_zero_padding (ZeroPadd (None, 17, 17, 512)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_44_conv_1 (Conv2D)        (None, 8, 8, 1024)   4719616     layer_44_zero_padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_44_bn_2 (BatchNormalizati (None, 8, 8, 1024)   4096        layer_44_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_44_leaky_3 (LeakyReLU)    (None, 8, 8, 1024)   0           layer_44_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_45_conv_1 (Conv2D)        (None, 8, 8, 512)    524800      layer_44_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_45_bn_2 (BatchNormalizati (None, 8, 8, 512)    2048        layer_45_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_45_leaky_3 (LeakyReLU)    (None, 8, 8, 512)    0           layer_45_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_46_conv_1 (Conv2D)        (None, 8, 8, 1024)   4719616     layer_45_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_46_bn_2 (BatchNormalizati (None, 8, 8, 1024)   4096        layer_46_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_46_leaky_3 (LeakyReLU)    (None, 8, 8, 1024)   0           layer_46_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 1024)   0           layer_46_leaky_3[0][0]           \n",
      "                                                                 layer_44_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_47_conv_1 (Conv2D)        (None, 8, 8, 512)    524800      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_47_bn_2 (BatchNormalizati (None, 8, 8, 512)    2048        layer_47_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_47_leaky_3 (LeakyReLU)    (None, 8, 8, 512)    0           layer_47_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_48_conv_1 (Conv2D)        (None, 8, 8, 1024)   4719616     layer_47_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_48_bn_2 (BatchNormalizati (None, 8, 8, 1024)   4096        layer_48_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_48_leaky_3 (LeakyReLU)    (None, 8, 8, 1024)   0           layer_48_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 1024)   0           layer_48_leaky_3[0][0]           \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_49_conv_1 (Conv2D)        (None, 8, 8, 512)    524800      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_49_bn_2 (BatchNormalizati (None, 8, 8, 512)    2048        layer_49_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_49_leaky_3 (LeakyReLU)    (None, 8, 8, 512)    0           layer_49_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_50_conv_1 (Conv2D)        (None, 8, 8, 1024)   4719616     layer_49_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_50_bn_2 (BatchNormalizati (None, 8, 8, 1024)   4096        layer_50_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_50_leaky_3 (LeakyReLU)    (None, 8, 8, 1024)   0           layer_50_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 1024)   0           layer_50_leaky_3[0][0]           \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_51_conv_1 (Conv2D)        (None, 8, 8, 512)    524800      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_51_bn_2 (BatchNormalizati (None, 8, 8, 512)    2048        layer_51_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_51_leaky_3 (LeakyReLU)    (None, 8, 8, 512)    0           layer_51_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_52_conv_1 (Conv2D)        (None, 8, 8, 1024)   4719616     layer_51_leaky_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_52_bn_2 (BatchNormalizati (None, 8, 8, 1024)   4096        layer_52_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_52_leaky_3 (LeakyReLU)    (None, 8, 8, 1024)   0           layer_52_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 1024)   0           layer_52_leaky_3[0][0]           \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pooling (AveragePooling2D)  (None, 4, 4, 1024)   0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16384)        0           avg_pooling[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 1000)         16385000    flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,023,496\n",
      "Trainable params: 56,987,784\n",
      "Non-trainable params: 35,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "darknet = darknet_53(input_shape)\n",
    "darknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的設置上，我故意很明顯又直白到簡直就是囉哩八唆的去設置layer的編號而不是用迴圈，為的就是能夠直觀說明，到最後的average pooling之前剛好是52，加上最後一個fully connected剛好53，也就是Darknet-53的由來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這是Darknet-53，不是YOLOv3，慢慢來，每天學一點，一天不要學太多東西。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
