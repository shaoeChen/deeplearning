{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這邊我會假設你已經看過[Darknet-53](https://github.com/shaoeChen/deeplearning/blob/master/tf2/Arch_YOLOv3_1_Darknet-53_structure.ipynb)的說明，而且你也已經完全明白模型的架構是怎麼一回事。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面先給出眾多的參考資料，瞭解一個架構不容易，參考的自然也多了，正確的寫出引用、參照是學習過程中的必要："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)\n",
    "* [pjreddie/darknet](https://github.com/pjreddie/darknet)\n",
    "* [YOLOv3_論文翻譯連結](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FryHg904h9)\n",
    "* [YOLOv3深度解析](https://blog.csdn.net/leviopku/article/details/82660381)\n",
    "* [qqwweee/keras-yolo3](https://github.com/qqwweee/keras-yolo3)\n",
    "* [YunYang1994/tensorflow-yolov3](https://github.com/YunYang1994/tensorflow-yolov3)\n",
    "* [joymyhome_Yolov3 config file中pad的理解](https://blog.csdn.net/joymyhome/article/details/106349084)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相關前置資料的處理可以參考另作[Arch_YOLOv2_dataset_preprocess.ipynb](https://github.com/shaoeChen/deeplearning/blob/master/tf2/Arch_YOLOv2_dataset_preprocess.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的docker上執行的版本為tensorflow 2.1，雖然現在流行人生苦短我用PyTorch，不過我還是先繼續tf + keras。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定使用的gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把建構Darknet的資料處理完畢，這邊不再做任何說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_conv(input_x, filters: int, filter_size: tuple, name: str, strides: int = 1, \n",
    "                is_activate: bool = True, is_bn: bool = True):\n",
    "    \"\"\"處理常規的捲積\n",
    "    \n",
    "    input_x: input tensor\n",
    "    filters: filter的數量\n",
    "    filter_size: filter size, ex (3, 3), (1, 1)\n",
    "    strides: 步幅，如果downsampling就會設置為2\n",
    "        _is_downsampling: 是否為下採樣，是的話就外推兩個邊，這部份可以透過strides來做判斷\n",
    "    is_activate: 是否含啟動函數，因為架構上的啟動函數都是leaky relu，所以設置為bool，只看有沒有\n",
    "    is_bn: 是否做batch normalization    \n",
    "    \"\"\" \n",
    "    _padding = 'same'\n",
    "    \n",
    "    if strides == 2:\n",
    "        input_x = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)), name=name + '_zero_padding')(input_x)\n",
    "        _padding = 'valid'\n",
    "        \n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=filters, \n",
    "                               kernel_size=filter_size, \n",
    "                               strides=strides,\n",
    "                               name=name + '_conv_1',\n",
    "                               padding=_padding\n",
    "                              )(input_x)\n",
    "    if is_activate:\n",
    "        x = tf.keras.layers.LeakyReLU(name=name + '_leaky_3')(x)\n",
    "        \n",
    "    if is_bn:\n",
    "        x = tf.keras.layers.BatchNormalization(name=name + '_bn_2')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(pre_output, filter_list: tuple, name_list: list):\n",
    "    \"\"\"從論文中的架構圖可以看的出來，residual block是由兩個conv layer建構起來\n",
    "    \n",
    "    pre_output: 前一個layer的output\n",
    "    filter_list:  兩次捲積的filter數量\n",
    "    name_list: 兩次捲積的layer name    \n",
    "    \"\"\"    \n",
    "    assert len(filter_list) == 2    \n",
    "    \n",
    "    filter_nums_1, filter_nums_2 = filter_list\n",
    "    layer_name_1 = 'layer_' + str(name_list[0])\n",
    "    layer_name_2 = 'layer_' + str(name_list[1])\n",
    "    \n",
    "    x = common_conv(pre_output, filters=filter_nums_1, filter_size=(1, 1), name=layer_name_1, strides=1)\n",
    "    x = common_conv(x, filters=filter_nums_2, filter_size=(3, 3), name=layer_name_2, strides=1)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([x, pre_output])\n",
    "    return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_reshape(l, n):\n",
    "    \"\"\"for list reshape\"\"\"\n",
    "    return [l[i: i+n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本上，[YOLOv3](https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg)的話跟darknet-53不是那麼一樣，darknet-53是它的結構的一部份。下面給出YOLOv3的結構圖。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hackmd.io/_uploads/rJJwnl5pq.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上圖是我自己看著[cfg檔](https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg)然後算啊算畫出來的一個YOLOv3的架構圖，最左邊的部份就是Darknet-53，不難發現，從Darknet裡面有三個output，這就是[論文2-3](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FryHg904h9#23-Predictions-Across-Scales)所提到的部份。現在我們就根據上面說明的部份來調整Darknet。  \n",
    "\n",
    "備註：不確定索引是不是應該從0開始算，如果是的話那37就會是36。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本上YOLOv3的架構非常的規律，還可以再做適度的封裝，不過這部份為了說明，我就不特別處理，就採用囉哩八唆的方式來呈現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_53(input_shape: tuple):\n",
    "    \"\"\"模型的概略部份可以參考上圖，詳細部份記得去看作者的git\n",
    "    \n",
    "    在YOLOv3中，會從darknet中取得三個output，分別是第36、61個layer以及最後的output，\n",
    "    值得注意的是，最後的output是沒有flatten、pool、softmax之類的操作。\n",
    "    \"\"\"\n",
    "    x_input = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = common_conv(x_input, filters=32, filter_size=(3, 3), name='layer_1', strides=1)\n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=64, filter_size=(3, 3), name='layer_2', strides=2)    \n",
    "    # 1x    \n",
    "    x = residual_block(x, filter_list=(32, 64), name_list=[3, 4])\n",
    "    \n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=128, filter_size=(3, 3), name='layer_5', strides=2)\n",
    "    # 2x\n",
    "    _name_list = easy_reshape(list(range(6, 10)), 2)\n",
    "    for i in range(2):\n",
    "        x = residual_block(x, filter_list=(64, 128), name_list=_name_list[i])   \n",
    "        \n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=256, filter_size=(3, 3), name='layer_10', strides=2)\n",
    "    # 8x\n",
    "    _name_list = easy_reshape(list(range(11, 27)), 2)\n",
    "    for i in range(8):\n",
    "        x = residual_block(x, filter_list=(128, 256), name_list=_name_list[i])\n",
    "        \n",
    "    # 36-layer\n",
    "    output_36 = x   \n",
    "    \n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=512, filter_size=(3, 3), name='layer_27', strides=2)\n",
    "    # 8x\n",
    "    _name_list = easy_reshape(list(range(28, 44)), 2)\n",
    "    for i in range(8):\n",
    "        x = residual_block(x, filter_list=(256, 512), name_list=_name_list[i])\n",
    "        \n",
    "    # 61-layer\n",
    "    output_61 = x\n",
    "    \n",
    "    # Downsample\n",
    "    x = common_conv(x, filters=1024, filter_size=(3, 3), name='layer_44', strides=2)\n",
    "    # 4x\n",
    "    _name_list = easy_reshape(list(range(45, 53)), 2)\n",
    "    for i in range(4):\n",
    "        x = residual_block(x, filter_list=(512, 1024), name_list=_name_list[i])\n",
    "        \n",
    "    \n",
    "    return output_36, output_61, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (416, 416, 3)\n",
    "output_36, output_61, output_last = darknet_53(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 52, 52, 256]),\n",
       " TensorShape([None, 26, 26, 512]),\n",
       " TensorShape([None, 13, 13, 1024]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_36.shape, output_61.shape, output_last.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在就來設置YOLOv3。每一個output的filter的數量會是255是因為：(類別(80個) + 座標(4個) + 置信度(1個)) * 預測框(3個)。論文中有提到，他是根據不同尺度來做預測，因此有不同大小的輸出。不同大小的輸出就可會體現在前面的NxN的部份，13x13、26x26、52x52，這代表的是我們把一張輸入的照片分割成NxN，然後每個grid cell都會有3個框的預測結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov3(input_shape: tuple):\n",
    "    \"\"\"YOLOv3\n",
    "    \n",
    "    input_shape: 輸入的維度\n",
    "    \n",
    "    從論文中我們知道，yolo的架構中會從darknet內取得三個output，再做後續的feature map的處理，\n",
    "    \n",
    "    \"\"\"\n",
    "    darknet_52x52, darknet_26x26, darknet_13x13 = darknet_53(input_shape)\n",
    "    \n",
    "    # 首先處理13x13x255的feature maps\n",
    "    \n",
    "    feature_13x13 = common_conv(darknet_13x13, filters=512, filter_size=(1, 1), name='yolo_13x13_1', strides=1)    \n",
    "    feature_13x13 = common_conv(feature_13x13, filters=1024, filter_size=(3, 3), name='yolo_13x13_2', strides=1)    \n",
    "    feature_13x13 = common_conv(feature_13x13, filters=512, filter_size=(1, 1), name='yolo_13x13_3', strides=1)    \n",
    "    feature_13x13 = common_conv(feature_13x13, filters=1024, filter_size=(3, 3), name='yolo_13x13_4', strides=1)    \n",
    "    feature_13x13 = common_conv(feature_13x13, filters=512, filter_size=(1, 1), name='yolo_13x13_5', strides=1)    \n",
    "        \n",
    "    # 這邊代表的就是13x13的那個結構中的第五次conv之後的output\n",
    "    yolo_13x13 = feature_13x13 \n",
    "    \n",
    "    feature_13x13 = common_conv(feature_13x13, filters=1024, filter_size=(3, 3), name='yolo_13x13_6', strides=1)            \n",
    "    # 這邊的輸出是對應上圖左二YOLO1\n",
    "    feature_13x13_output = common_conv(feature_13x13, filters=255, filter_size=(1, 1), name='yolo_13x13_7', \n",
    "                                       strides=1, is_activate=False, is_bn=False)\n",
    "    \n",
    "    # 這邊處理的是26x26的feature map\n",
    "    # 先從yolo 13x13中過來的feature map會先做上採樣，也就是upsampling之後再跟darknet取得的26x26的feature map結合\n",
    "    feature_26x26 = common_conv(yolo_13x13, filters=256, filter_size=(1, 1), name='yolo_26x26_input', strides=1)\n",
    "    feature_26x26 = tf.keras.layers.UpSampling2D(name='yolo_26x26_upsampling')(feature_26x26)\n",
    "    feature_26x26 = tf.keras.layers.Concatenate()([feature_26x26, darknet_26x26])\n",
    "    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=256, filter_size=(1, 1), name='yolo_26x26_1', strides=1)    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=512, filter_size=(3, 3), name='yolo_26x26_2', strides=1)    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=256, filter_size=(1, 1), name='yolo_26x26_3', strides=1)    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=512, filter_size=(3, 3), name='yolo_26x26_4', strides=1)    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=256, filter_size=(1, 1), name='yolo_26x26_5', strides=1)  \n",
    "    \n",
    "    # 這邊代表的就是26x26的那個結構中的第五次conv之後的output\n",
    "    yolo_26x26 = feature_26x26\n",
    "    \n",
    "    feature_26x26 = common_conv(feature_26x26, filters=512, filter_size=(3, 3), name='yolo_26x26_6', strides=1)    \n",
    "    feature_26x26_output = common_conv(feature_26x26, filters=255, filter_size=(1, 1), name='yolo_26x26_7', \n",
    "                                       strides=1, is_activate=False, is_bn=False)\n",
    "    \n",
    "    \n",
    "    # 這邊處理的是52x52的feature map\n",
    "    # 先從yolo 26x26中過來的feature map會先做上採樣，也就是upsampling之後再跟darknet取得的52x52的feature map結合\n",
    "    feature_52x52 = common_conv(yolo_26x26, filters=128, filter_size=(1, 1), name='yolo_52x52_input', strides=1)\n",
    "    feature_52x52 = tf.keras.layers.UpSampling2D(name='yolo_52x52_upsampling')(feature_52x52)\n",
    "    feature_52x52 = tf.keras.layers.Concatenate()([feature_52x52, darknet_52x52])\n",
    "    \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=128, filter_size=(1, 1), name='yolo_52x52_1', strides=1)    \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=256, filter_size=(3, 3), name='yolo_52x52_2', strides=1)    \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=128, filter_size=(1, 1), name='yolo_52x52_3', strides=1)    \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=256, filter_size=(3, 3), name='yolo_52x52_4', strides=1)    \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=128, filter_size=(1, 1), name='yolo_52x52_5', strides=1)      \n",
    "    feature_52x52 = common_conv(feature_52x52, filters=256, filter_size=(3, 3), name='yolo_52x52_6', strides=1)    \n",
    "    feature_52x52_output = common_conv(feature_52x52, filters=255, filter_size=(1, 1), name='yolo_52x52_7', \n",
    "                                       strides=1, is_activate=False, is_bn=False)\n",
    "    \n",
    "    \n",
    "    return feature_13x13_output, feature_26x26_output, feature_52x52_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_13x13, yolo_26x26, yolo_52x52 = yolov3(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 13, 13, 255]),\n",
       " TensorShape([None, 26, 26, 255]),\n",
       " TensorShape([None, 52, 52, 255]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_13x13.shape, yolo_26x26.shape, yolo_52x52.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到這邊也算是成功的把YOLOv3的骨幹弄起來了，每天學一點，一天不要學太多東西。後續就可以來處理訓練YOLOv3的問題。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
